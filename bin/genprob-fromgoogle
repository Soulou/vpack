#!/usr/bin/env python

def main(argv=None):
    from argparse import ArgumentParser
    from gzip import GzipFile
    import os
    import random
    import sys

    import pandas as pd

    parser = ArgumentParser(
        description="Generat a random problem instance using google data.")
    parser.add_argument('-s', '--seed', type=int, 
                        help='seed for random number generator')
    parser.add_argument('-g', '--googledir', 
                        help='path to google-clusterdata-2011-1 directory')
    parser.add_argument('-i', '--indexfile', 
                        help='path to google task_usage-startend-index file')

    parser.add_argument('-c', '--cpuslack', help='cpu slack')

    parser.add_argument('-m', '--memslack', help='memory slack')
    args = parser.parse_args()

    random.seed(args.seed) 

    # get task population data from google dataset
    file_index = pd.read_csv(
        args.indexfile, header=None, index_col=False,
        names=['filename', 'min_timestamp', 'max_timestamp'])
    min_timestamp = min(file_index['min_timestamp'])
    max_timestamp = max(file_index['max_timestamp'])
    moment = random.randint(min_timestamp, max_timestamp)
    task_population = dict()
    file_list = file_index[(file_index['min_timestamp'] <= moment) &
                       (moment <= file_index['max_timestamp'])]['filename']

    usage_data = pd.concat(
        pd.read_csv(
                 os.path.join(args.googledir, 'task_usage', fname),
                 compression='gzip',
                 names=['start_time', 'end_time', 
                        'job_id', 'task_idx', 'machine_id', 
                        'cpu_rate', 'canonical_mem_usage', 
                        'assigned_mem_usage', 
                        'unmapped_page_cache', 'total_page_cache', 
                        'max_mem_usage', 'disk_io', 'local_disk_space_usage', 
                        'max_cpu_rate', 'max_disk_io_time', 'cpi', 'mapi', 
                        'sample_portion', 'agg_type'])
        for fname in file_list)
    task_population = usage_data[(usage_data['start_time'] <= moment) &
                            (moment <= usage_data['end_time']) &
                            ((usage_data['cpu_rate'] > 0.0) |
                             (usage_data['canonical_mem_usage'] > 0.0))]

    # get machine data from google
    machine_events = pd.read_csv(
        os.path.join(args.googledir, 
                     'machine_events/part-00000-of-00001.csv.gz'),
        compression='gzip',
        names=['timestamp', 'machine_id', 'event_type', 'platform_id', 
               'cpu', 'mem'])
    machine_events = machine_events[machine_events['timestamp'] <= moment].sort(
        columns=['timestamp'])
   
    machine_stats = dict()
    for index, event in machine_events.iterrows():
        event_type = event['event_type']
        machine_id = event['machine_id']
        cpu = event['cpu']
        mem = event['mem']
        if event_type in [0, 2]:
            machine_stats[machine_id] = (machine_id, cpu, mem)
        elif event_type == 1:
            del machine_stats[machine_id]

    machine_population = pd.DataFrame(machine_stats.values(), 
                                      columns=['machine_id', 'cpu', 'mem'])
            
    task_sample = random.sample(
        list(task_population[['cpu_rate', 'canonical_mem_usage']].itertuples()),
        4096)
    machine_sample = random.sample(
        list(machine_population[['cpu', 'mem']].itertuples()), 512)

if __name__ == "__main__":
    main()
